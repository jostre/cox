{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194bcb8c-7369-458b-b2b7-3edc0bfd371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73884b6b-44b4-41fc-9399-087f1fd21a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARLSON_CONDITIONS = {\n",
    "    'mi': {\n",
    "        '9': [\"410\", \"412\"],\n",
    "        '10': [\"I21\", \"I22\", \"I25.2\"]\n",
    "    },\n",
    "    'chf': {\n",
    "        '9': [\"398.91\", \"402.01\",\"402.11\",\"402.91\",\"404.01\",\"404.03\",\"404.11\",\"404.13\",\"404.91\",\"404.93\",\"425.4\",\"425.5\",\"425.6\",\"425.7\",\"425.8\",\"425.9\",\"428\"],\n",
    "        '10': [\"I09.9\", \"I11.0\", \"I13.0\", \"I13.2\", \"I25.5\", \"I42.0\", \"I42.5\", \"I42.6\", \"I42.7\", \"I42.8\", \"I42.9\", \"I43\", \"I50\", \"P29.0\"]\n",
    "    },\n",
    "    'pvd': {\n",
    "        '9': [\"093.0\", \"440\",\"441\",\"443.1\",\"443.2\",\"443.3\",\"443.4\",\"443.5\",\"443.6\",\"443.7\",\"443.8\",\"443.9\",\"557.1\",\"557.9\",\"V43.4\"],\n",
    "        '10': [\"I70\", \"I71\", \"I73.1\",\"I73.8\",\"I73.9\",\"I77.1\",\"I79.0\",\"I79.2\",\"K55.1\",\"K55.8\",\"K55.9\",\"Z95.8\",\"Z95.9\"]\n",
    "    },\n",
    "    'cevd': {\n",
    "        '9': [\"362.34\", \"430\",\"431\",\"432\",\"433\",\"434\",\"435\",\"436\",\"437\",\"438\"],\n",
    "        '10': [\"G45\", \"G46\", \"H34.0\",\"I60\", \"I61\", \"I62\",\"I63\",\"I64\",\"I65\",\"I66\",\"I67\",\"I68\",\"I69\"]\n",
    "    },\n",
    "    'dementia': {\n",
    "        '9': [\"290\",\"294.1\",\"331.2\"],\n",
    "        '10': [\"F00\",\"F01\",\"F02\",\"F03\",\"F05.1\",\"G30\",\"G31.1\"]\n",
    "    },\n",
    "    'copd': {\n",
    "        '9': [\"416.8\",\"416.9\",\"490\", \"491\",\"492\",\"493\",\"494\",\"495\",\"496\",\"497\",\"498\",\"499\",\"500\",\"501\",\"502\",\"503\",\"504\",\"505\",\"506.4\",\"508.1\", \"508.8\"],\n",
    "        '10': [\"I27.8\",\"I27.9\",\"J40\", \"J41\", \"J42\",\"J43\",\"J44\",\"J45\",\"J46\",\"J47\",\"J60\",\"J61\",\"J62\",\"J63\",\"J64\",\"J65\",\"J66\",\"J67\",\"J68.4\",\"J70.1\", \"J70.3\"]\n",
    "    },\n",
    "    'rheumd': {\n",
    "        '9': [\"446.5\", \"710.0\", \"710.1\", \"710.2\", \"710.3\", \"710.4\", \"714.0\", \"714.1\", \"714.2\", \"714.8\", \"725\"],\n",
    "        '10': [\"M05\", \"M06\", \"M31.5\", \"M32\", \"M33\", \"M34\", \"M35.1\", \"M35.3\", \"M36.0\"]\n",
    "    },\n",
    "    'pud': {\n",
    "        '9': [\"531\", \"532\", \"533\", \"534\"],\n",
    "        '10': [\"K25\", \"K26\", \"K27\", \"K28\"]\n",
    "    },\n",
    "    'mld': {\n",
    "        '9': [\"070.22\", \"070.23\", \"070.32\", \"070.33\", \"070.44\", \"070.54\", \"070.6\", \"070.9\", \"570\", \"571\", \"573.3\", \"573.4\", \"573.8\", \"573.9\", \"V42.7\"],\n",
    "        '10': [\"B18\", \"K70.0\", \"K70.1\", \"K70.2\", \"K70.3\", \"K70.9\", \"K71.3\", \"K71.4\", \"K71.5\", \"K71.7\", \"K73\", \"K74\", \"K76.0\", \"K76.2\", \"K76.3\", \"K76.4\", \"K76.8\", \"K76.9\", \"Z94.4\"]\n",
    "    },\n",
    "    'msld': {\n",
    "        '9': [\"456.0\", \"456.1\", \"456.2\", \"572.2\", \"572.3\", \"572.4\",\"572.5\",\"572.6\",\"572.7\", \"572.8\"],\n",
    "        '10': [\"I85.0\",\"I85.9\", \"I86.4\",\"I98.2\", \"K70.4\", \"K71.1\", \"K72.1\", \"K72.9\", \"K76.5\", \"K76.6\", \"K76.7\"]\n",
    "    },\n",
    "    'diab': {\n",
    "        '9': [\"250.0\", \"250.1\", \"250.2\", \"250.3\", \"250.8\", \"250.9\"],\n",
    "        '10': [\"E10.0\", \"E10.1\", \"E10.6\", \"E10.8\",\"E10.9\",\"E11.0\",\"E11.1\",\"E11.6\",\"E11.8\",\"E11.9\",\"E13.0\",\"E13.1\",\"E13.6\",\"E13.8\",\"E13.9\"]\n",
    "    },\n",
    "    'dia_w_c': {\n",
    "        '9': [\"250.4\", \"250.5\", \"250.6\", \"250.7\"],\n",
    "        '10': [\"E10.2\", \"E10.3\", \"E10.4\", \"E10.5\", \"E10.7\", \"E11.2\", \"E11.3\", \"E11.4\", \"E11.5\", \"E11.7\", \"E13.2\", \"E13.3\", \"E13.4\", \"E13.5\", \"E13.7\"]\n",
    "    },\n",
    "    'hp': {\n",
    "        '9': [\"334.1\", \"342\", \"343\", \"344.0\",\"344.1\",\"344.2\",\"344.3\",\"344.4\",\"344.5\",\"344.6\",\"344.9\"],\n",
    "        '10': [\"G04.1\", \"G11.4\", \"G80.1\", \"G80.2\", \"G81\", \"G82\", \"G83.0\",\"G83.1\",\"G83.2\",\"G83.3\",\"G83.4\",\"G83.9\"]\n",
    "    },\n",
    "    'mrend': {\n",
    "        '9': [\"403.00\",\"403.10\", \"403.90\", \"404.00\", \"404.01\", \"404.10\", \"404.11\", \"404.90\", \"404.91\", \"584\", \"585.6\", \"589\"],\n",
    "        '10': [\"I12.9\",\"I13.0\",\"I13.10\",\"N03\", \"N05\",\"N18.1\", \"N18.2\",\"N18.3\",\"N18.4\",\"N18.9\", \"Z49.0\"]\n",
    "    },\n",
    "    'srend': {\n",
    "        '9': [\"403.01\", \"403.11\", \"403.91\", \"404.02\", \"404.03\", \"404.12\", \"404.13\", \"404.92\", \"404.93\",\"582\",\"583.0\",\"583.1\",\"583.2\",\"583.3\",\"583.4\",\"583.5\",\"583.6\",\"583.7\",\"585.5\", \"585.6\",\"586\",\"588.0\",\"V42.0\",\"V45.1\",\"V56\"],\n",
    "        '10': [\"I12.0\", \"I13.11\",\"I13.2\",\"N18.5\",\"N18.6\",\"N19\", \"N25.0\",\"Z49\",\"Z94.0\", \"Z99.2\"]\n",
    "    },\n",
    "    'aids': {\n",
    "        '9': [\"112\", \"180\", \"114\", \"117.5\", \"007.4\", \"078.5\", \"348.3\", \"054\", \"115\", \"007.2\", \"176\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"031\", \"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"136.3\", \"V12.61\", \"046.3\", \"003.1\", \"130\", \"799.4\"],\n",
    "        '10': [\"B37\", \"C53\", \"B38\", \"B45\", \"A07.2\", \"B25\", \"G93.4\", \"B00\", \"B39\", \"A07.3\", \"C46\", \"C81\", \"C82\", \"C83\", \"C84\", \"C85\", \"C86\", \"C87\", \"C88\", \"C89\", \"C90\", \"C91\", \"C92\", \"C93\", \"C94\", \"C95\", \"C96\", \"A31\", \"A15\", \"A16\", \"A17\", \"A18\", \"A19\", \"B59\", \"Z87.01\", \"A81.2\", \"A02.1\", \"B58\", \"R64\"]\n",
    "    },\n",
    "    'hiv': {\n",
    "        '9': [\"042\"],\n",
    "        '10': [\"B20\"]\n",
    "    },\n",
    "    'mst': {\n",
    "        '9': [\"196\", \"197\", \"198\", \"199.0\"],\n",
    "        '10': [\"C77\", \"C78\", \"C79\", \"C80.0\", \"C80.2\"]\n",
    "    },\n",
    "    'mal': {\n",
    "        '9': [\"14\", \"15\", \"16\", \"170\", \"171\", \"172\", \"174\", \"175\", \"176\", \"179\", \"18\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"199.1\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"238.6\"],\n",
    "        '10': [\"C0\", \"C1\", \"C2\", \"C30\", \"C31\", \"C32\", \"C33\", \"C34\", \"C37\", \"C38\", \"C39\", \"C40\", \"C41\", \"C43\", \"C45\", \"C46\", \"C47\", \"C48\", \"C49\", \"C50\", \"C51\",\"C52\",\"C53\",\"C54\",\"C55\",\"C56\",\"C57\", \"C58\", \"C60\",\"C61\",\"C62\", \"C63\", \"C76\", \"C80.1\", \"C81\", \"C82\", \"C83\", \"C84\", \"C85\", \"C88\", \"C9\"]\n",
    "    },\n",
    "    'Obesity': {\n",
    "        '9': [\"278.0\"],\n",
    "        '10': [\"E66\"]\n",
    "    },\n",
    "    'WL': {\n",
    "        '9': ['260','261','262','263','783.2','799.4'],\n",
    "        '10': ['E40','E41','E42','E43','E44','E45','E46','R63.4','R64']\n",
    "    },\n",
    "    'Alcohol': {\n",
    "        '9': ['265.2','291.1','291.2','291.3','291.5','291.8','291.9','303.0','303.9','305.0','357.5','425.5','535.3','571.0','571.1','5712','5713','980','V113'],\n",
    "        '10': ['F10','E52','G62.1','I42.6','K29.2','K70.0','K70.3','K70.9','T51','Z50.2','Z71.4','Z72.1']\n",
    "    },\n",
    "    'Drug': {\n",
    "        '9': ['292','304','305.2','305.3','305.4','305.5','305.6','305.7','305.8','305.9','V65.42'],\n",
    "        '10': ['F11','F12','F13','F14','F15','F16','F18','F19','Z71.5','Z72.2']\n",
    "    },\n",
    "    'Psycho': {\n",
    "        '9': ['293.8','295','296.04','296.14','296.44','296.54','297','298'],\n",
    "        '10': ['F20','F22','F23','F24','F25','F28','F29','F30.2','F31.2','F31.5']\n",
    "    },\n",
    "    'Dep': {\n",
    "        '9': ['296.2','296.3','296.5','300.4','309','311'],\n",
    "        '10': ['F20.4','F31.3','F31.4','F31.5','F32','F33','F34.1','F41.2','F43.2']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40330e1d-4b51-4b25-95af-46cc451aba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weight: 1.0500000000000003\n"
     ]
    }
   ],
   "source": [
    "CONDITION_WEIGHTS = {\n",
    "    'mi': 0.04,       \n",
    "    'chf': 0.06,      \n",
    "    'pvd': 0.05,      \n",
    "    'cevd': 0.05,      \n",
    "    'dementia': 0.04,  \n",
    "    'copd': 0.08,      \n",
    "    'rheumd': 0.04,    \n",
    "    'pud': 0.04,       \n",
    "    'mld': 0.05,       \n",
    "    'msld': 0.03,     \n",
    "    'diab': 0.08,      \n",
    "    'dia_w_c': 0.06,   \n",
    "    'hp': 0.04,        \n",
    "    'mrend': 0.05,     \n",
    "    'srend': 0.04,     \n",
    "    'aids': 0.03,      \n",
    "    'hiv': 0.02,       \n",
    "    'mst': 0.03,       \n",
    "    'mal': 0.05,       \n",
    "    'Obesity': 0.04,   \n",
    "    'WL': 0.03,        \n",
    "    'Alcohol': 0.03,   \n",
    "    'Drug': 0.02,      \n",
    "    'Psycho': 0.02,    \n",
    "    'Dep': 0.03        \n",
    "}\n",
    "\n",
    "total_weight = sum(CONDITION_WEIGHTS.values())\n",
    "print(f\"Total weight: {total_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983c2421-fe8b-4357-89ec-48faf5f687cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    \"\"\"Create SQLite database and tables\"\"\"\n",
    "    conn = sqlite3.connect('healthcare.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create tables\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS provider (\n",
    "        provider_id TEXT PRIMARY KEY,\n",
    "        latitude REAL,\n",
    "        longitude REAL\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS geolocation (\n",
    "        patient_id TEXT PRIMARY KEY,\n",
    "        census_block TEXT,\n",
    "        latitude REAL,\n",
    "        longitude REAL\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS travel_time (\n",
    "        census_block TEXT,\n",
    "        provider_id TEXT,\n",
    "        travel_time_type TEXT,\n",
    "        travel_time_minutes REAL,\n",
    "        PRIMARY KEY (census_block, provider_id, travel_time_type)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS demographics (\n",
    "        patient_id TEXT PRIMARY KEY,\n",
    "        birth_date DATE,\n",
    "        sex TEXT,\n",
    "        race TEXT,\n",
    "        ethnicity TEXT,\n",
    "        education TEXT,\n",
    "        income REAL\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS rucc (\n",
    "        census_block TEXT PRIMARY KEY,\n",
    "        rucc_code INTEGER\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS encounter (\n",
    "        patient_id TEXT,\n",
    "        encounter_id TEXT PRIMARY KEY,\n",
    "        start_date DATE,\n",
    "        end_date DATE\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS procedure_table (\n",
    "        patient_id TEXT,\n",
    "        encounter_id TEXT,\n",
    "        provider_id TEXT,\n",
    "        procedure_code TEXT,\n",
    "        start_datetime DATETIME,\n",
    "        end_datetime DATETIME,\n",
    "        FOREIGN KEY (encounter_id) REFERENCES encounter(encounter_id)\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS diagnosis (\n",
    "        patient_id TEXT,\n",
    "        encounter_id TEXT,\n",
    "        diagnosis_code TEXT,\n",
    "        vocabulary_id TEXT,\n",
    "        diagnosis_date DATE,\n",
    "        FOREIGN KEY (patient_id) REFERENCES demographics(patient_id),\n",
    "        FOREIGN KEY (encounter_id) REFERENCES encounter(encounter_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "def load_existing_data(conn, patient_locations, clinic_locations, travel_times):\n",
    "    \"\"\"Load existing location and travel time data, and RUCC data\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # clear all\n",
    "    cursor.execute('DELETE FROM provider')\n",
    "    cursor.execute('DELETE FROM geolocation')\n",
    "    cursor.execute('DELETE FROM travel_time')\n",
    "    cursor.execute('DELETE FROM demographics')\n",
    "    cursor.execute('DELETE FROM rucc')\n",
    "    cursor.execute('DELETE FROM encounter')\n",
    "    cursor.execute('DELETE FROM procedure_table')\n",
    "    cursor.execute('DELETE FROM diagnosis')\n",
    "    \n",
    "    # Load provider (clinic) data\n",
    "    provider_data = []\n",
    "    for i, (lat, lon) in enumerate(clinic_locations):\n",
    "        provider_id = f'PR{str(i+1).zfill(3)}'\n",
    "        provider_data.append((provider_id, lat, lon))\n",
    "    \n",
    "    cursor.executemany('INSERT INTO provider (provider_id, latitude, longitude) VALUES (?, ?, ?)',\n",
    "                      provider_data)\n",
    "    \n",
    "    # Load patient location data\n",
    "    patient_data = []\n",
    "    for i, location in enumerate(patient_locations):  # patient_locations\n",
    "        patient_id = f'P{str(i+1).zfill(3)}'       # P-ID: P001-P100\n",
    "        census_block = f'CB{str(i).zfill(3)}'      # census block: CB000-CB099\n",
    "        patient_data.append((\n",
    "            patient_id,\n",
    "            census_block,\n",
    "            location['lat'],\n",
    "            location['lon']\n",
    "        ))\n",
    "            \n",
    "    cursor.executemany('INSERT INTO geolocation (patient_id, census_block, latitude, longitude) VALUES (?, ?, ?, ?)',\n",
    "                      patient_data)\n",
    "    \n",
    "    # Load travel time data\n",
    "    travel_time_data = []\n",
    "    seen_combinations = set()\n",
    "    \n",
    "    for i, times in enumerate(travel_times):\n",
    "        census_block = f'CB{str(i).zfill(3)}'\n",
    "        for j, time in enumerate(times.values()):\n",
    "            provider_id = f'PR{str(j+1).zfill(3)}'\n",
    "            combination = (census_block, provider_id, 'DRIVING')\n",
    "            \n",
    "            if combination not in seen_combinations:\n",
    "                seen_combinations.add(combination)\n",
    "                travel_time_data.append((census_block, provider_id, 'DRIVING', float(time) * 60))\n",
    "    \n",
    "    cursor.executemany('INSERT INTO travel_time (census_block, provider_id, travel_time_type, travel_time_minutes) VALUES (?, ?, ?, ?)',\n",
    "                      travel_time_data)\n",
    "\n",
    "    # Load RUCC data from CSV\n",
    "    rucc_df = pd.read_csv('rucc_codes.csv')\n",
    "    rucc_data = [(row['census_block'], row['rucc_code']) \n",
    "                 for _, row in rucc_df.iterrows()]\n",
    "    \n",
    "    cursor.executemany('INSERT INTO rucc (census_block, rucc_code) VALUES (?, ?)',\n",
    "                      rucc_data)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "def generate_mock_data(conn, n_patients=100):\n",
    "    \"\"\"Generate mock demographic and medical data\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Generate demographics with correlations\n",
    "    current_date = datetime.now()\n",
    "    demographics_data = []\n",
    "    for i in range(n_patients):\n",
    "        patient_id = f'P{str(i+1).zfill(3)}'\n",
    "        \n",
    "        # Age between 45-80\n",
    "        age = np.random.normal(62, 10)\n",
    "        age = max(45, min(80, age))\n",
    "        birth_date = current_date - timedelta(days=int(age*365.25))\n",
    "        \n",
    "        # Correlated demographics\n",
    "        education_level = np.random.choice(\n",
    "            ['High School', 'Some College', 'Bachelor', 'Graduate'],\n",
    "            p=[0.3, 0.3, 0.25, 0.15]\n",
    "        )\n",
    "        \n",
    "        # Income correlated with education\n",
    "        base_income = {\n",
    "            'High School': 40000,\n",
    "            'Some College': 55000,\n",
    "            'Bachelor': 70000,\n",
    "            'Graduate': 85000\n",
    "        }\n",
    "        income = np.random.normal(base_income[education_level], 10000)\n",
    "        \n",
    "        demographics_data.append((\n",
    "            patient_id,\n",
    "            birth_date.strftime('%Y-%m-%d'),\n",
    "            np.random.choice(['M', 'F']),\n",
    "            np.random.choice(['White', 'Black', 'Asian', 'Other'], p=[0.7, 0.15, 0.1, 0.05]),\n",
    "            np.random.choice(['Hispanic', 'Non-Hispanic'], p=[0.15, 0.85]),\n",
    "            education_level,\n",
    "            income\n",
    "        ))\n",
    "    \n",
    "    cursor.executemany('''\n",
    "    INSERT INTO demographics \n",
    "    (patient_id, birth_date, sex, race, ethnicity, education, income)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', demographics_data)\n",
    "    \n",
    "    # Generate encounters and procedures\n",
    "    encounter_data = []\n",
    "    procedure_data = []\n",
    "    \n",
    "    for i in range(n_patients):\n",
    "        patient_id = f'P{str(i+1).zfill(3)}'\n",
    "        \n",
    "        # 1-3 encounters per patient\n",
    "        n_encounters = np.random.randint(1, 4)\n",
    "        \n",
    "        for j in range(n_encounters):\n",
    "            encounter_id = f'E{patient_id}_{j}'\n",
    "            \n",
    "            # Generate dates within last 2 years\n",
    "            start_date = current_date - timedelta(days=np.random.randint(1, 730))\n",
    "            end_date = start_date + timedelta(days=np.random.randint(1, 5))\n",
    "            \n",
    "            encounter_data.append((\n",
    "                patient_id,\n",
    "                encounter_id,\n",
    "                start_date.strftime('%Y-%m-%d'),\n",
    "                end_date.strftime('%Y-%m-%d')\n",
    "            ))\n",
    "            \n",
    "            # 30% chance of CRC screening procedure\n",
    "            if np.random.random() < 0.3:\n",
    "                procedure_code = np.random.choice(['45378', '45380', '45384', '45385'])\n",
    "                provider_id = f'PR{str(np.random.randint(1, 17)).zfill(3)}'\n",
    "                \n",
    "                procedure_start = datetime.combine(start_date, \n",
    "                                                datetime.strptime(f\"{np.random.randint(9,17)}:00\", \"%H:%M\").time())\n",
    "                procedure_end = procedure_start + timedelta(hours=np.random.randint(1, 4))\n",
    "                \n",
    "                procedure_data.append((\n",
    "                    patient_id,\n",
    "                    encounter_id,\n",
    "                    provider_id,\n",
    "                    procedure_code,\n",
    "                    procedure_start.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    procedure_end.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                ))\n",
    "    \n",
    "    cursor.executemany('''\n",
    "    INSERT INTO encounter \n",
    "    (patient_id, encounter_id, start_date, end_date)\n",
    "    VALUES (?, ?, ?, ?)\n",
    "    ''', encounter_data)\n",
    "    \n",
    "    cursor.executemany('''\n",
    "    INSERT INTO procedure_table \n",
    "    (patient_id, encounter_id, provider_id, procedure_code, start_datetime, end_datetime)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', procedure_data)\n",
    "\n",
    "    # Generate diagnosis data with Charlson Comorbidities\n",
    "    diagnosis_data = []\n",
    "    for encounter in encounter_data:\n",
    "        patient_id = encounter[0]\n",
    "        encounter_id = encounter[1]\n",
    "        start_date = datetime.strptime(encounter[2], '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(encounter[3], '%Y-%m-%d')\n",
    "        \n",
    "        # 30% pat with 1-3 diseases:\n",
    "        if np.random.random() < 0.3:\n",
    "            \n",
    "            n_conditions = np.random.randint(1, 4)\n",
    "            \n",
    "            selected_conditions = random.choices(\n",
    "                list(CONDITION_WEIGHTS.keys()),\n",
    "                weights=list(CONDITION_WEIGHTS.values()),\n",
    "                k=n_conditions\n",
    "            )\n",
    "            \n",
    "            for condition in selected_conditions:\n",
    "                # ICO version (80% ICD-10, 20% ICD-9)\n",
    "                version = '10' if random.random() < 0.8 else '9'\n",
    "                \n",
    "                # get codes from CHARLSON_CONDITIONS\n",
    "                codes = CHARLSON_CONDITIONS[condition][version]\n",
    "                selected_code = random.choice(codes)\n",
    "                \n",
    "                # generate diagnosis time\n",
    "                diag_datetime = start_date + timedelta(\n",
    "                    hours=random.randint(0, 24)\n",
    "                )\n",
    "                \n",
    "                diagnosis_data.append((\n",
    "                    patient_id,\n",
    "                    encounter_id,\n",
    "                    selected_code,\n",
    "                    f'ICD{version}CM',\n",
    "                    diag_datetime.strftime('%Y-%m-%d')\n",
    "                ))\n",
    "\n",
    "    cursor.executemany('''\n",
    "    INSERT INTO diagnosis \n",
    "    (patient_id, encounter_id, diagnosis_code, vocabulary_id, diagnosis_date)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', diagnosis_data)\n",
    "    \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd0f9be-2182-4e07-b154-7d2337184852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data(conn):\n",
    "    \"\"\"Verify the generated data and show key statistics\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"Table Record Counts:\")\n",
    "    print(\"-\" * 50)\n",
    "    for table in ['provider', 'geolocation', 'travel_time', 'demographics', 'rucc', 'encounter', 'procedure_table']:\n",
    "        count = cursor.execute(f'SELECT COUNT(*) FROM {table}').fetchone()[0]\n",
    "        print(f\"{table}: {count} records\")\n",
    "    \n",
    "    print(\"\\nSample Patient Data:\")\n",
    "    print(\"-\" * 50)\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        g.patient_id,\n",
    "        g.census_block,\n",
    "        d.sex,\n",
    "        d.birth_date,\n",
    "        d.education,\n",
    "        d.race,\n",
    "        d.ethnicity,\n",
    "        r.rucc_code,\n",
    "        COUNT(DISTINCT e.encounter_id) as num_encounters,\n",
    "        COUNT(DISTINCT p.procedure_code) as num_procedures,\n",
    "        MIN(t.travel_time_minutes) as min_travel_time\n",
    "    FROM geolocation g\n",
    "    JOIN demographics d ON g.patient_id = d.patient_id\n",
    "    JOIN rucc r ON g.census_block = r.census_block\n",
    "    LEFT JOIN encounter e ON g.patient_id = e.patient_id\n",
    "    LEFT JOIN procedure_table p ON e.encounter_id = p.encounter_id\n",
    "    LEFT JOIN travel_time t ON g.census_block = t.census_block\n",
    "    GROUP BY g.patient_id\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(df)\n",
    "    \n",
    "    print(\"\\nKey Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Charlson Comorbidities\n",
    "    print(\"\\nCharlson Comorbidities Distribution:\")\n",
    "    for condition, codes in CHARLSON_CONDITIONS.items():\n",
    "        query = f\"\"\"\n",
    "        SELECT COUNT(DISTINCT patient_id) as count\n",
    "        FROM diagnosis\n",
    "        WHERE (vocabulary_id = 'ICD9CM' AND diagnosis_code IN ('{\"','\".join(codes['9'])}'))\n",
    "        OR (vocabulary_id = 'ICD10CM' AND diagnosis_code IN ('{\"','\".join(codes['10'])}'))\n",
    "        \"\"\"\n",
    "        count = cursor.execute(query).fetchone()[0]\n",
    "        print(f\"{condition}: {count} patients\")\n",
    "    \n",
    "    screening_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT CASE WHEN procedure_code IN ('45378', '45380', '45384', '45385') \n",
    "              THEN patient_id END) * 100.0 / COUNT(DISTINCT patient_id) as screening_rate\n",
    "    FROM procedure_table\n",
    "    \"\"\"\n",
    "    screening_rate = pd.read_sql_query(screening_query, conn).iloc[0,0]\n",
    "    print(f\"CRC Screening Rate: {screening_rate:.1f}%\")\n",
    "    \n",
    "    encounters_query = \"\"\"\n",
    "    SELECT AVG(encounter_count) as avg_encounters\n",
    "    FROM (\n",
    "        SELECT patient_id, COUNT(*) as encounter_count\n",
    "        FROM encounter\n",
    "        GROUP BY patient_id\n",
    "    )\n",
    "    \"\"\"\n",
    "    avg_encounters = pd.read_sql_query(encounters_query, conn).iloc[0,0]\n",
    "    print(f\"Average encounters per patient: {avg_encounters:.1f}\")\n",
    "    \n",
    "    # Travel time \n",
    "    travel_time_query = \"\"\"\n",
    "    SELECT \n",
    "        MIN(travel_time_minutes) as min_time,\n",
    "        AVG(travel_time_minutes) as avg_time,\n",
    "        MAX(travel_time_minutes) as max_time\n",
    "    FROM travel_time\n",
    "    \"\"\"\n",
    "    travel_times = pd.read_sql_query(travel_time_query, conn)\n",
    "    print(\"\\nTravel Time Distribution (minutes):\")\n",
    "    print(f\"Min: {travel_times.iloc[0,0]:.1f}\")\n",
    "    print(f\"Avg: {travel_times.iloc[0,1]:.1f}\")\n",
    "    print(f\"Max: {travel_times.iloc[0,2]:.1f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2815e370-9bfa-46f7-ba46-eca8074053d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tables_to_csv(conn):\n",
    "    \"\"\"Export all tables from database to CSV files\"\"\"\n",
    "    tables = [\n",
    "        'geolocation', 'demographics', 'encounter', \n",
    "        'procedure_table', 'provider', 'rucc', 'travel_time','diagnosis'\n",
    "    ]\n",
    "    \n",
    "    for table in tables:\n",
    "        query = f\"SELECT * FROM {table}\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        df.to_csv(f'{table}.csv', index=False)\n",
    "        print(f\"Exported {table}.csv with {len(df)} rows\")\n",
    "\n",
    "        print(f\"\\nFirst few rows of {table}:\")\n",
    "        print(df.head())\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "def close_all_connections():\n",
    "    import sqlite3\n",
    "    sqlite3.connect('healthcare.db').close()\n",
    "\n",
    "def ensure_fresh_database():\n",
    "    import os\n",
    "    if os.path.exists('healthcare.db'):\n",
    "        try:\n",
    "            os.remove('healthcare.db')\n",
    "        except PermissionError:\n",
    "            print(\"Could not remove existing database. Please close any programs that might be using it.\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "\n",
    "    close_all_connections()\n",
    "    \n",
    "    if not ensure_fresh_database():\n",
    "        return\n",
    "    \n",
    "    conn = create_database()\n",
    "\n",
    "    try:\n",
    "        # Load your existing data\n",
    "        with open('sampled_block_group_centers_100_30.json', 'r') as f:\n",
    "            patient_locations = json.load(f)\n",
    "            \n",
    "        clinic_locations = [\n",
    "            [40.40655, -86.8321528],\n",
    "            [40.7344392, -86.77769099999999],\n",
    "            [40.2765035, -86.4970488],\n",
    "            [39.9164485, -86.1557417],\n",
    "            [39.7805894, -86.3405844],\n",
    "            [39.7775523, -86.1837364],\n",
    "            [39.79052859999999, -86.16338739999999],\n",
    "            [39.7756075, -86.1761174],\n",
    "            [39.9868449, -85.929307],\n",
    "            [39.6379321, -86.1593584],\n",
    "            [40.2247576, -85.4507319],\n",
    "            [39.2893255, -86.7867983],\n",
    "            [39.9075207, -85.3861367],\n",
    "            [39.1606644, -86.55537140000001],\n",
    "            [38.8599541, -86.51307659999999],\n",
    "            [38.56829949999999, -86.47532799999999]\n",
    "        ]\n",
    "        \n",
    "        with open('ExactTravelTimeDatafromAllMatrix.json', 'r') as f:\n",
    "            travel_times = json.load(f)\n",
    "        \n",
    "        # Load existing data into database and generate mock data\n",
    "        load_existing_data(conn, patient_locations, clinic_locations, travel_times)\n",
    "        generate_mock_data(conn)\n",
    "\n",
    "        # verify data\n",
    "        verify_data(conn)\n",
    "        \n",
    "        # Export all tables to CSV\n",
    "        export_tables_to_csv(conn)\n",
    "        \n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d7030d-fe4a-4e0c-9a63-cc23a686c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Record Counts:\n",
      "--------------------------------------------------\n",
      "provider: 16 records\n",
      "geolocation: 100 records\n",
      "travel_time: 1600 records\n",
      "demographics: 100 records\n",
      "rucc: 100 records\n",
      "encounter: 198 records\n",
      "procedure_table: 59 records\n",
      "\n",
      "Sample Patient Data:\n",
      "--------------------------------------------------\n",
      "  patient_id census_block sex  birth_date     education   race     ethnicity  \\\n",
      "0       P001        CB000   M  1961-04-05  Some College  White  Non-Hispanic   \n",
      "1       P002        CB001   F  1971-02-02   High School  White  Non-Hispanic   \n",
      "2       P003        CB002   F  1955-12-05      Bachelor  Black  Non-Hispanic   \n",
      "3       P004        CB003   M  1961-07-27   High School  White  Non-Hispanic   \n",
      "4       P005        CB004   F  1980-02-20      Bachelor  Other  Non-Hispanic   \n",
      "\n",
      "   rucc_code  num_encounters  num_procedures  min_travel_time  \n",
      "0          2               2               1        69.600000  \n",
      "1          1               3               1        16.983333  \n",
      "2          6               1               0        80.650000  \n",
      "3          1               2               0        13.533333  \n",
      "4          8               1               0        64.133333  \n",
      "\n",
      "Key Statistics:\n",
      "--------------------------------------------------\n",
      "\n",
      "Charlson Comorbidities Distribution:\n",
      "mi: 5 patients\n",
      "chf: 8 patients\n",
      "pvd: 5 patients\n",
      "cevd: 5 patients\n",
      "dementia: 9 patients\n",
      "copd: 9 patients\n",
      "rheumd: 5 patients\n",
      "pud: 5 patients\n",
      "mld: 4 patients\n",
      "msld: 3 patients\n",
      "diab: 10 patients\n",
      "dia_w_c: 5 patients\n",
      "hp: 6 patients\n",
      "mrend: 6 patients\n",
      "srend: 8 patients\n",
      "aids: 3 patients\n",
      "hiv: 5 patients\n",
      "mst: 4 patients\n",
      "mal: 8 patients\n",
      "Obesity: 5 patients\n",
      "WL: 3 patients\n",
      "Alcohol: 6 patients\n",
      "Drug: 1 patients\n",
      "Psycho: 4 patients\n",
      "Dep: 5 patients\n",
      "CRC Screening Rate: 100.0%\n",
      "Average encounters per patient: 2.0\n",
      "\n",
      "Travel Time Distribution (minutes):\n",
      "Min: 3.3\n",
      "Avg: 108.2\n",
      "Max: 266.1\n",
      "Exported geolocation.csv with 100 rows\n",
      "\n",
      "First few rows of geolocation:\n",
      "  patient_id census_block   latitude  longitude\n",
      "0       P001        CB000  41.068899 -85.204652\n",
      "1       P002        CB001  39.718917 -86.234499\n",
      "2       P003        CB002  38.627923 -85.502788\n",
      "3       P004        CB003  40.036595 -85.985839\n",
      "4       P005        CB004  39.574533 -84.880974\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported demographics.csv with 100 rows\n",
      "\n",
      "First few rows of demographics:\n",
      "  patient_id  birth_date sex   race     ethnicity     education        income\n",
      "0       P001  1961-04-05   M  White  Non-Hispanic  Some College  61625.334943\n",
      "1       P002  1971-02-02   F  White  Non-Hispanic   High School  28938.942644\n",
      "2       P003  1955-12-05   F  Black  Non-Hispanic      Bachelor  67233.017908\n",
      "3       P004  1961-07-27   M  White  Non-Hispanic   High School  38548.349438\n",
      "4       P005  1980-02-20   F  Other  Non-Hispanic      Bachelor  73818.983733\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported encounter.csv with 198 rows\n",
      "\n",
      "First few rows of encounter:\n",
      "  patient_id encounter_id  start_date    end_date\n",
      "0       P001      EP001_0  2024-02-07  2024-02-08\n",
      "1       P001      EP001_1  2024-03-17  2024-03-19\n",
      "2       P002      EP002_0  2023-12-13  2023-12-16\n",
      "3       P002      EP002_1  2024-05-20  2024-05-21\n",
      "4       P002      EP002_2  2025-01-20  2025-01-21\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported procedure_table.csv with 59 rows\n",
      "\n",
      "First few rows of procedure_table:\n",
      "  patient_id encounter_id provider_id procedure_code       start_datetime  \\\n",
      "0       P001      EP001_1       PR001          45378  2024-03-17 09:00:00   \n",
      "1       P002      EP002_1       PR008          45380  2024-05-20 13:00:00   \n",
      "2       P009      EP009_2       PR008          45384  2025-02-13 14:00:00   \n",
      "3       P010      EP010_1       PR014          45380  2024-08-30 15:00:00   \n",
      "4       P010      EP010_2       PR005          45384  2024-07-26 09:00:00   \n",
      "\n",
      "          end_datetime  \n",
      "0  2024-03-17 11:00:00  \n",
      "1  2024-05-20 14:00:00  \n",
      "2  2025-02-13 16:00:00  \n",
      "3  2024-08-30 16:00:00  \n",
      "4  2024-07-26 12:00:00  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported provider.csv with 16 rows\n",
      "\n",
      "First few rows of provider:\n",
      "  provider_id   latitude  longitude\n",
      "0       PR001  40.406550 -86.832153\n",
      "1       PR002  40.734439 -86.777691\n",
      "2       PR003  40.276503 -86.497049\n",
      "3       PR004  39.916449 -86.155742\n",
      "4       PR005  39.780589 -86.340584\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported rucc.csv with 100 rows\n",
      "\n",
      "First few rows of rucc:\n",
      "  census_block  rucc_code\n",
      "0        CB000          2\n",
      "1        CB001          1\n",
      "2        CB002          6\n",
      "3        CB003          1\n",
      "4        CB004          8\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported travel_time.csv with 1600 rows\n",
      "\n",
      "First few rows of travel_time:\n",
      "  census_block provider_id travel_time_type  travel_time_minutes\n",
      "0        CB000       PR001          DRIVING           126.766667\n",
      "1        CB000       PR002          DRIVING           111.850000\n",
      "2        CB000       PR003          DRIVING           116.866667\n",
      "3        CB000       PR004          DRIVING           105.266667\n",
      "4        CB000       PR005          DRIVING           126.416667\n",
      "\n",
      "==================================================\n",
      "\n",
      "Exported diagnosis.csv with 132 rows\n",
      "\n",
      "First few rows of diagnosis:\n",
      "  patient_id encounter_id diagnosis_code vocabulary_id diagnosis_date\n",
      "0       P002      EP002_1          E11.2       ICD10CM     2024-05-20\n",
      "1       P004      EP004_1          416.9        ICD9CM     2024-08-03\n",
      "2       P004      EP004_1          M35.3       ICD10CM     2024-08-03\n",
      "3       P004      EP004_1            B20       ICD10CM     2024-08-03\n",
      "4       P007      EP007_0            436        ICD9CM     2024-12-17\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d86e0-0bf4-4fbb-aa73-d06103e65cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
